{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mạng nơ-ron\n",
    "\n",
    "Mạng nơ-ron được xây dựng dựa trên ý tưởng mô phỏng lại cách hoạt động của bộ não con người. \n",
    "- Mỗi nơ-ron nhận tín hiệu truyền vào, xử lý tín hiệu và tiếp tục gửi tín hiệu đến nơ-ron kế tiếp cho đến khi tín hiệu được xử lý hoàn tất (forward). \n",
    "- Sau đó, thông tin về việc xử lý tín hiệu được truyền ngược lại thông qua một cung phản xạ đến nơ-ron phát tín hiệu ban đầu (backward).\n",
    "\n",
    "Một mạng nơ-ron bắt buộc phải có một tầng đầu vào và một tầng đầu ra. Các tầng ẩn có thể có hoặc không.\n",
    "\n",
    "<img src=\"multi_layers.png\" style=\"width:50%; text-align:center\">\n",
    "\n",
    "Trên đây là một hình vẽ mô tả mạng nơ-ron đầy đủ với tầng đầu vào (`input`), 2 tầng ẩn (`hidden layer`) và tầng đầu ra (`output`). `W` là các trọng số dùng để biến đổi tín hiệu truyền từ nơ-ron này sang nơ-ron khác (hay từ lớp này sang lớp khác).\n",
    "\n",
    "Trong bài học này, chúng ta sẽ làm quen với cách xây dựng một mô hình mạng nơ-ron nhân tạo sử dụng thư viện **Keras**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import một số thư viện cần thiết.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "\n",
    "# Sử dụng một mẹo nhỏ để vẽ hình trên cùng một dòng thay vì mở cửa sổ mới\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # đặt kích thước mặc định cho hình\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Một mẹo nhỏ để notebook tự load lại các module bên ngoài;\n",
    "# xem thêm tại http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tải dữ liệu Cifar10 từ Keras và chia thành dữ liệu huấn luyện và kiểm tra.\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "# Dữ liệu CIFAR10 gồm 50,000 ảnh màu kích thước 32x32 để huấn luyện, gồm 10 chuyên mục, và 10,000 ảnh kiểm tra.\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# As a sanity check, we print out the size of the training and test data.\n",
    "print('Training data shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hiển thị một số ảnh từ trong bộ dữ liệu.\n",
    "# Với mỗi lớp, chúng ta sẽ hiển thị một số ảnh minh họa.\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = 7\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.flatnonzero(y_train == y)\n",
    "    idxs = np.random.choice(idxs, samples_per_class, replace=False)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lấy 1 phần nhỏ dữ liệu để huấn luyện hiệu quả hơn trong bài tập này\n",
    "num_training = 5000\n",
    "mask = range(num_training)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "num_test = 500\n",
    "mask = range(num_test)\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Định dạng lại hình ảnh thành các hàng\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xây dựng mô hình với Keras\n",
    "\n",
    "**Keras** là một API mạng nơ-ron bậc cao, viết bằng ngôn ngữ Python và có thể chạy trên nền của `Tensorflow`, `CNTK` hay `Theano`.  `Keras` được phát triển với trọng tâm là cho phép người phát triển xây dựng những thử nghiệm nhanh chóng, đi từ ý tưởng đến kết quả với ít chậm trễ nhất.\n",
    "\n",
    "Cấu trúc dữ liệu cốt lõi của **Keras** là mô hình, cách để tổ chức các lớp. \n",
    "\n",
    "Để xây dựng một mô hình trong **Keras**, ta có 2 cách:\n",
    "- Xây dụng mô hình tuần tự (Sequential model) *hoặc*\n",
    "- Xây dựng API chức năng (Functional API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mô hình tuần tự\n",
    "**Mô hình tuần tự** là loại mô hình đơn giản nhất trong **Keras**, là một ngăn xếp tuyến tính các lớp. Để xây dựng mô hình tuần tự, ta thêm lần lượt các lớp theo thứ tự vào trong mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import mô hình tuần tự từ thư viện Keras\n",
    "from keras.models import Sequential\n",
    "\n",
    "# khởi tạo biến model là một ngăn xếp chứa các lớp\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense\n",
    "**Dense** được sử dụng để cài đặt biểu thức **output = activation(dot(input, kernel) + bias)**\n",
    "\n",
    "Trong đó:\n",
    "- **activation** là hàm kích hoạt trong một nơ-ron (một lớp), được truyền qua tham số **activation**;\n",
    "- **kernel** là ma trận trọng số của từng lớp;\n",
    "- **bias** là véc-tơ sai số của từng lớp.\n",
    "\n",
    "Tìm hiểu thêm về **Dense** tại [đây](https://keras.io/layers/core/#dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Dense để tạo ra các lớp trong ngăn xếp model\n",
    "from keras.layers import Dense\n",
    "\n",
    "# sử dụng hàm add() để thêm lớp vào trong ngăn xếp\n",
    "# Tham số:\n",
    "#    - input_shape hay input_dim: thể hiện kích thước hay số chiều của dữ liệu đầu vào\n",
    "#    - units: số chiều của dữ liệu tại đầu ra của lớp hiện thời\n",
    "#    - activation (optional): hàm kích hoạt được sử dụng trong lớp (mặc định là hàm tuyến tính: a(x) = x)\n",
    "\n",
    "# lấy kích thước của dữ liệu đầu vào\n",
    "# input_dim: số chiều của mỗi dữ liệu\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# input_shape gồm số lượng dữ liệu và số chiều của mỗi dữ liệu\n",
    "input_shape = X_train.shape\n",
    "\n",
    "# lớp đầu vào có đầu ra dữ liệu là 64 và không sử dụng hàm kích hoạt\n",
    "model.add(Dense(units=1024, input_dim=input_dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hàm kích hoạt (Activation)\n",
    "**Hàm kích hoạt** được sử dụng để biến đổi tín hiệu đầu vào của một nơ-ron thành tín hiệu đầu ra phù hợp để tiếp tục truyền đi đến nơ-ron tiếp theo.\n",
    "\n",
    "Ta có thể truyền hàm kích hoạt vào trong mô hình như một tham số của lớp **Dense** hoặc truyền riêng biệt sử dụng lớp **Activation**.\n",
    "\n",
    "Một số hàm kích hoạt thường sử dụng trong `Keras`: `sigmoid`, `softmax`, `tanh`, `relu`, `softplus`. Tìm hiểu thêm về các hàm kích hoạt tại [đây](https://keras.io/activations/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import lớp Activation\n",
    "from keras.layers import Activation\n",
    "\n",
    "# sử dụng hàm add() để thêm lớp Activation vào mô hình \n",
    "# (trước đó tầng ẩn đã được thêm vào với hàm model.add(Dense()))\n",
    "# hàm kích hoạt được sử dụng là sigmoid\n",
    "model.add(Activation('sigmoid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bài tập: ** Cài đặt thêm hai tẩng ẩn và tầng đầu ra vào mô hình với:\n",
    "- Tầng thứ nhất: số chiều đầu ra là **512** và sử dụng hàm kích hoạt **tanh**;\n",
    "- Tầng thứ hai: số chiều đầu ra là **128** và sử dụng hàm kích hoạt **relu**.\n",
    "- Tầng đầu ra: số chiều đầu ra là **1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code tại đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biên dịch\n",
    "Sau khi xây dựng được cấu trúc các lớp trong ngăn xếp, ta cần chỉ ra quá trình học của mô hình thông qua hàm **compile()** trước khi huấn luyện mô hình.\n",
    "\n",
    "Hàm này nhận 3 tham số quan trọng:\n",
    "- Bộ tối ưu hóa (**optimizer**). Là một chuỗi xác định bộ tối ưu hóa đã được cài đặt sẵn (chẳng hạn như `rmsprop` hay `adam`) hay một thể hiện của lớp [**Optimizer**](https://keras.io/optimizers/). \n",
    "- Hàm mất mát (**loss**). Đây là đối tượng mô hình cần cực tiểu hóa. Nó là một xâu xác định tên hàm mất mát đã được cài đặt (ví dụ `categorical_crossentropy ` hay `mse`), hoặc một đối tượng hàm, chi tiết xem tại [đây.](https://keras.io/losses/)\n",
    "- Danh sách metric (**metrics**). Trong bài toán phân lớp, ta thường chọn `metrics=['accuracy']`.\n",
    "\n",
    "Tham khảo thêm tại [đây](https://keras.io/getting-started/sequential-model-guide/#compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ví dụ về việc định nghĩa quá trình học của mô hình với\n",
    "# bộ tối ưu là 'rmsprop', hàm mất mát là 'mse' (mean square error)\n",
    "# và list metric là 'accuracy' \n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Bài tập:** Biên dịch lại mô hình với hàm mất mát là **hinge**, tối ưu hóa bởi **adam** và trả về danh sách metrics **accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code tại đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huấn luyện mô hình\n",
    "Các mô hình của **Keras** được huấn luyện trên các mảng **Numpy** của dữ liệu đầu vào và nhãn. Để huấn luyện một mô hình, cần sử dụng hàm **fit()**.\n",
    "\n",
    "Một số tham số quan trọng của hàm **fit()**:\n",
    "- **x**: Ddữ liệu huấn luyện dưới dạng mảng numpy;\n",
    "- **y**: Nhãn dữ liệu tương ứng với dữ liệu huấn luyện (mảng numpy);\n",
    "- **batch_size**: Số lượng dữ liệu trong mỗi lần cập nhật gradient (kiểu nguyên hoặc `None`). Giá trị mặc định là `32`.\n",
    "- **epochs**: Số lượng giai đoạn để huấn luyện mô hình (kiểu nguyên).\n",
    "\n",
    "Tìm hiểu thêm về các hàm liên quan tại [đây](https://keras.io/models/sequential/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Huấn luyện mô hình dựa trên dữ liệu huấn luyện X_train, y_train\n",
    "# Lặp lại quá trình học với epochs=10 và batch_size=32\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm **fit()** trả về **History** lưu lại lịch sử cập nhật của mô hình. Ta có thể vẽ lại được sự thay đổi của mô hình dựa trên thuộc tính **History.history**, nó lưu lại các giá trị hàm mất mát (`loss`) và giá trị metric tương ứng (`acc`) qua mỗi giai đoạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xây dựng biểu đồ thể hiện lịch sử thay đổi của mô hình qua mỗi giai đoạn\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title(\"Loss value\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.legend(['loss'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "**Bài tập:** Huấn luyện lại mô hình với số epochs là **100** và batch_size bằng **64**. Sử dụng một biến để lưu lại giá trị trả về của hàm **fit()**, dựa vào đó, vẽ lại biểu đồ sự thay đổi của metric qua các giai đoạn.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code ở đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dự đoán\n",
    "\n",
    "Sau khi huấn luyện, mô hình được đánh giá với dữ liệu kiểm tra bằng hàm **evaluate()**.\n",
    "\n",
    "Hàm nhận 3 tham số quan trọng lần lượt là:\n",
    "- **x**: Dữ liệu kiểm tra (kiểu mảng Numpy);\n",
    "- **y**: Nhãn tương ứng với dữ liệu kiểm tra (kiểu mảng Numpy);\n",
    "- **batch_size**: Số lượng ví dụ được dùng trong mỗi lần cập nhật gradient (kiểu nguyên). Mặc định là **32**.\n",
    "\n",
    "Hàm trả về một mảng số thực **score** chứa giá trị hàm mất mát (**loss**) và giá trị metric (**accuracy**). Nếu mô hình không có metric, **score** là giá trị mất mát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API chức năng\n",
    "**API chức năng** là lựa chọn tối ưu trong việc xây dựng mạng kết nối với mật độ cao (các lớp không liên kết tuần tự trong ngăn xếp).\n",
    "\n",
    "Các lớp có thể đồng thời là đầu vào của nhiều lớp kế tiếp, bằng cách sử dụng đầu ra của lớp đó như một tham số truyền vào của một hàm của lớp khác.\n",
    "\n",
    "Xây dựng một mô hình với **API chức năng** về cơ bản giống với xây dựng **mô hình tuần tự**. Điều khác nhau duy nhất là quá trình xây dựng cấu trúc các lớp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import thêm lớp Input để khởi tạo mô hình\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "# khởi tạo một thể hiện của lớp Input\n",
    "# tham số shape (kiểu tuple) là kích thước của dữ liệu đầu vào (số chiều dữ liệu)\n",
    "# giá trị trả về là một tensor\n",
    "input_dim = X_train.shape[1]\n",
    "inputs = Input(shape=(input_dim,))\n",
    "\n",
    "# mỗi thể hiện của một lớp có thể được gọi bởi một tensor\n",
    "# và kết quả trả về là một tensor\n",
    "# thêm một tầng ẩn gọi đến tensor inputs\n",
    "x = Dense(64, activation=\"sigmoid\")(inputs)\n",
    "\n",
    "# ... có thể thêm nhiều tầng ẩn ở giữa ...\n",
    "\n",
    "# tầng đầu ra của mô hình với số chiều 1\n",
    "predictions = Dense(1)(x)\n",
    "\n",
    "# Tạo ra mô hình mới bao gồm tầng đầu vào và các tầng ẩn (kết thúc bằng tensor predictions)\n",
    "api_model = Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phần còn lại của quá trình xây dựng **API chức năng** tương tự như **Mô hình tuần tự**.\n",
    "\n",
    "Tham khảo thêm tại [đây](https://keras.io/getting-started/functional-api-guide/)\n",
    "\n",
    "**Bài tập:** Tiếp tục hoàn thiện quá trình xây dụng **API chức năng** (biên dịch và huấn luyện mô hình). Sử dụng kết quả **History** trong quá trình huấn luyện để vẽ ra đồ thị thay đổi của giá trị mất mát trong các giai đoạn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code ở đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập\n",
    "Xây dựng mô hình (bằng **API chức năng** hoặc **Mô hình tuần tự**) sao cho hiệu năng (`acc`) trên tập kiểm tra đạt trên 15%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code ở đây"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
